{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XstQcr6KZbTV"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/exercises/4_ex_data_prep.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhjDMKBTZbTV"
   },
   "source": [
    "# BADS Exercise 4 on data preparation\n",
    "This exercise revisits some of the concepts covered in [Tutorial 4 on data preparation](https://github.com/Humboldt-WI/bads/blob/master/tutorials/4_nb_data_preparation.ipynb). That tutorial was rather comprehensive and provided a lot of materials and codes associated with typical tasks in the wide scope of data preparation. Therefore, the exercises will not go beyond [Tutorial 4](https://github.com/Humboldt-WI/bads/blob/master/tutorials/4_nb_data_preparation.ipynb). Rather, we will consider a different data set and repeat some standard data prep. tasks for that data set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space to load some standard libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhjDMKBTZbTV"
   },
   "source": [
    "## 1 Loading the data \n",
    "The data set for this tutorial comes from the classic Book Credit Scoring and its Applications by Lyn C. Thomas, David B. Edelman, and Jonathan N. Crook. You can obtain the data, called *loan_data* from our [GitHub repository](https://github.com/Humboldt-WI/bads/tree/master/data). The data folder of the repository also provides a file *loan_data_dictionary*, which offers a brief description of the features in this data set. In a nutshell, the data represents yet another vanilla credit scoring task with a binary target variable, indicating whether bank customers repaid their debt or defaulted, and a few features characterizing credit applicants. Your first task is to load the data into a `Pandas DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1638948271923,
     "user": {
      "displayName": "Stefan Lessmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihtuVUIO07jrZ6NKEVggi44vrPvluMzUCsHoZh=s64",
      "userId": "06342662613942148717"
     },
     "user_tz": -60
    },
    "id": "bgGuosuKZbTV",
    "outputId": "9ee0947d-80dc-4674-82ec-3a430abdbc23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOB</th>\n",
       "      <th>nKIDS</th>\n",
       "      <th>nDEP</th>\n",
       "      <th>PHON</th>\n",
       "      <th>dINC_SP</th>\n",
       "      <th>EMPS_A</th>\n",
       "      <th>dINC_A</th>\n",
       "      <th>RES</th>\n",
       "      <th>dHVAL</th>\n",
       "      <th>dMBO</th>\n",
       "      <th>dOUTM</th>\n",
       "      <th>dOUTL</th>\n",
       "      <th>dOUTHP</th>\n",
       "      <th>dOUTCC</th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>14464.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>464.0</td>\n",
       "      <td>O</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>37764.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>P</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>O</td>\n",
       "      <td>6928.0</td>\n",
       "      <td>46464.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>46800.0</td>\n",
       "      <td>O</td>\n",
       "      <td>11392.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>5538.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1225 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       YOB  nKIDS  nDEP  PHON  dINC_SP EMPS_A   dINC_A RES    dHVAL     dMBO  \\\n",
       "0     19.0    4.0   0.0     1      0.0      R      0.0   O  14464.0      4.0   \n",
       "1     41.0    2.0   0.0     1      0.0      P  36000.0   O      0.0      0.0   \n",
       "2     66.0    0.0   0.0     1      0.0      N  30000.0   N      0.0      0.0   \n",
       "3     51.0    2.0   0.0     1      0.0      P    464.0   O  24928.0   8464.0   \n",
       "4     65.0    0.0   0.0     1      0.0      P  15000.0   P      0.0      0.0   \n",
       "...    ...    ...   ...   ...      ...    ...      ...  ..      ...      ...   \n",
       "1220  52.0    4.0   1.0     1      0.0      V  37764.0   U      0.0      0.0   \n",
       "1221  56.0    3.0   0.0     1   1200.0      P  31500.0   O   6928.0  46464.0   \n",
       "1222  60.0    0.0   0.0     1      0.0      E  46800.0   O  11392.0    928.0   \n",
       "1223  20.0    0.0   0.0     1      0.0      R      0.0   N      0.0      0.0   \n",
       "1224  66.0    0.0   0.0     1      0.0      T   5538.0   P      0.0      0.0   \n",
       "\n",
       "       dOUTM  dOUTL  dOUTHP  dOUTCC  BAD  \n",
       "0        0.0    0.0     0.0     0.0  0.0  \n",
       "1      280.0  664.0     0.0    80.0  0.0  \n",
       "2        0.0    0.0     0.0     0.0  0.0  \n",
       "3      584.0  320.0     0.0    60.0  0.0  \n",
       "4        0.0    0.0     0.0     0.0  0.0  \n",
       "...      ...    ...     ...     ...  ...  \n",
       "1220     0.0  340.0     0.0     0.0  0.0  \n",
       "1221   784.0  256.0     0.0     0.0  1.0  \n",
       "1222  1144.0  680.0     0.0   108.0  0.0  \n",
       "1223     0.0    0.0     0.0     0.0  1.0  \n",
       "1224   492.0    0.0     0.0     0.0  0.0  \n",
       "\n",
       "[1225 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data directly from GitHub\n",
    "\n",
    "# Despite the fact that CSV stands for coma separated values, it also supports using\n",
    "# other symbols to distinguish values from different columns. If you open `loan_data.csv` \n",
    "# in a text editor, you will see that values are in fact separated with a semi-colon.\n",
    "# Therefore, we need to specify sep = ';' in `pd.read_csv()` to tell pandas which \n",
    "# symbol to use to separate one column from another. You can try importing the data \n",
    "# without specifying sep (default is ',') and check the summary to see why it does\n",
    "# not work as expected. As always, be sure to check pandas documentation to learn\n",
    "# more about different options when importing the data.\n",
    "data_url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/loan_data.csv'\n",
    "df       = pd.read_csv(data_url, sep = ';')\n",
    "\n",
    "# Summary of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqw_wcW2ZbTW"
   },
   "source": [
    "By now, you have run through the process of getting a first idea about a new data set many times. You have seen examples in previous tutorials and have written your own codes in, e.g., the third exercise on predictive analytics. Nonetheless, draw once more on your experience and take a quick look into the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZfKUAryeDY2",
    "outputId": "d1e8ea62-4cca-4a9e-c07d-e5fa9f104839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 15\n",
      "Number of cases:     1225\n"
     ]
    }
   ],
   "source": [
    "# Check data dimensions \n",
    "print('Number of variables: {}'.format(df.shape[1])) \n",
    "print('Number of cases:     {}'.format(df.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "Q_Lfg0zPZbTW",
    "outputId": "1410f69f-5c74-4fd6-808f-15fc72724780"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOB</th>\n",
       "      <th>nKIDS</th>\n",
       "      <th>nDEP</th>\n",
       "      <th>PHON</th>\n",
       "      <th>dINC_SP</th>\n",
       "      <th>EMPS_A</th>\n",
       "      <th>dINC_A</th>\n",
       "      <th>RES</th>\n",
       "      <th>dHVAL</th>\n",
       "      <th>dMBO</th>\n",
       "      <th>dOUTM</th>\n",
       "      <th>dOUTL</th>\n",
       "      <th>dOUTHP</th>\n",
       "      <th>dOUTCC</th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>14464.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>464.0</td>\n",
       "      <td>O</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>E</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>O</td>\n",
       "      <td>43392.0</td>\n",
       "      <td>46464.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>O</td>\n",
       "      <td>62464.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YOB  nKIDS  nDEP  PHON  dINC_SP EMPS_A   dINC_A RES    dHVAL     dMBO  \\\n",
       "0  19.0    4.0   0.0     1      0.0      R      0.0   O  14464.0      4.0   \n",
       "1  41.0    2.0   0.0     1      0.0      P  36000.0   O      0.0      0.0   \n",
       "2  66.0    0.0   0.0     1      0.0      N  30000.0   N      0.0      0.0   \n",
       "3  51.0    2.0   0.0     1      0.0      P    464.0   O  24928.0   8464.0   \n",
       "4  65.0    0.0   0.0     1      0.0      P  15000.0   P      0.0      0.0   \n",
       "5  42.0    2.0   0.0     1  10500.0      E  48000.0   O  43392.0  46464.0   \n",
       "6  59.0    0.0   0.0     1   6500.0      B  30000.0   O  62464.0  56000.0   \n",
       "\n",
       "    dOUTM  dOUTL  dOUTHP  dOUTCC  BAD  \n",
       "0     0.0    0.0     0.0     0.0  0.0  \n",
       "1   280.0  664.0     0.0    80.0  0.0  \n",
       "2     0.0    0.0     0.0     0.0  0.0  \n",
       "3   584.0  320.0     0.0    60.0  0.0  \n",
       "4     0.0    0.0     0.0     0.0  0.0  \n",
       "5  1120.0    0.0     0.0     0.0  0.0  \n",
       "6   520.0    0.0    96.0     0.0  0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine top-7 rows of the data\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "v0RSS-2zec8B",
    "outputId": "2e1d2924-16f4-46a6-c9b9-7ecb708e2aa0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOB</th>\n",
       "      <th>nKIDS</th>\n",
       "      <th>nDEP</th>\n",
       "      <th>PHON</th>\n",
       "      <th>dINC_SP</th>\n",
       "      <th>EMPS_A</th>\n",
       "      <th>dINC_A</th>\n",
       "      <th>RES</th>\n",
       "      <th>dHVAL</th>\n",
       "      <th>dMBO</th>\n",
       "      <th>dOUTM</th>\n",
       "      <th>dOUTL</th>\n",
       "      <th>dOUTHP</th>\n",
       "      <th>dOUTCC</th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.037551</td>\n",
       "      <td>0.623673</td>\n",
       "      <td>0.038367</td>\n",
       "      <td>0.903673</td>\n",
       "      <td>1990.084898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21244.211429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15693.857959</td>\n",
       "      <td>11225.691429</td>\n",
       "      <td>342.004898</td>\n",
       "      <td>121.926531</td>\n",
       "      <td>28.721633</td>\n",
       "      <td>39.595102</td>\n",
       "      <td>0.263673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.301818</td>\n",
       "      <td>1.016013</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0.295159</td>\n",
       "      <td>4802.341425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15896.207986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20736.331833</td>\n",
       "      <td>18889.207107</td>\n",
       "      <td>427.993865</td>\n",
       "      <td>839.639588</td>\n",
       "      <td>119.324084</td>\n",
       "      <td>168.697101</td>\n",
       "      <td>0.440804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19500.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30600.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28928.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44280.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50464.000000</td>\n",
       "      <td>46464.000000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>390.400000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64800.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64928.000000</td>\n",
       "      <td>64000.000000</td>\n",
       "      <td>3800.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                YOB        nKIDS         nDEP         PHON       dINC_SP  \\\n",
       "count   1225.000000  1225.000000  1225.000000  1225.000000   1225.000000   \n",
       "unique          NaN          NaN          NaN          NaN           NaN   \n",
       "top             NaN          NaN          NaN          NaN           NaN   \n",
       "freq            NaN          NaN          NaN          NaN           NaN   \n",
       "mean      51.037551     0.623673     0.038367     0.903673   1990.084898   \n",
       "std       15.301818     1.016013     0.219917     0.295159   4802.341425   \n",
       "min        3.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "10%       28.400000     0.000000     0.000000     1.000000      0.000000   \n",
       "25%       42.000000     0.000000     0.000000     1.000000      0.000000   \n",
       "50%       55.000000     0.000000     0.000000     1.000000      0.000000   \n",
       "75%       63.000000     1.000000     0.000000     1.000000   1040.000000   \n",
       "90%       67.000000     2.000000     0.000000     1.000000   8000.000000   \n",
       "max       99.000000     5.000000     2.000000     1.000000  50000.000000   \n",
       "\n",
       "       EMPS_A        dINC_A   RES         dHVAL          dMBO        dOUTM  \\\n",
       "count    1225   1225.000000  1225   1225.000000   1225.000000  1225.000000   \n",
       "unique     11           NaN     5           NaN           NaN          NaN   \n",
       "top         P           NaN     O           NaN           NaN          NaN   \n",
       "freq      531           NaN   624           NaN           NaN          NaN   \n",
       "mean      NaN  21244.211429   NaN  15693.857959  11225.691429   342.004898   \n",
       "std       NaN  15896.207986   NaN  20736.331833  18889.207107   427.993865   \n",
       "min       NaN      0.000000   NaN      0.000000      0.000000     0.000000   \n",
       "10%       NaN      0.000000   NaN      0.000000      0.000000     0.000000   \n",
       "25%       NaN   9000.000000   NaN      0.000000      0.000000     0.000000   \n",
       "50%       NaN  19500.000000   NaN      0.000000      0.000000   256.000000   \n",
       "75%       NaN  30600.000000   NaN  28928.000000  20000.000000   528.000000   \n",
       "90%       NaN  44280.000000   NaN  50464.000000  46464.000000   840.000000   \n",
       "max       NaN  64800.000000   NaN  64928.000000  64000.000000  3800.000000   \n",
       "\n",
       "               dOUTL       dOUTHP       dOUTCC          BAD  \n",
       "count    1225.000000  1225.000000  1225.000000  1225.000000  \n",
       "unique           NaN          NaN          NaN          NaN  \n",
       "top              NaN          NaN          NaN          NaN  \n",
       "freq             NaN          NaN          NaN          NaN  \n",
       "mean      121.926531    28.721633    39.595102     0.263673  \n",
       "std       839.639588   119.324084   168.697101     0.440804  \n",
       "min         0.000000     0.000000     0.000000     0.000000  \n",
       "10%         0.000000     0.000000     0.000000     0.000000  \n",
       "25%         0.000000     0.000000     0.000000     0.000000  \n",
       "50%         0.000000     0.000000     0.000000     0.000000  \n",
       "75%         0.000000     0.000000     0.000000     1.000000  \n",
       "90%       390.400000    42.400000   100.000000     1.000000  \n",
       "max     28000.000000  1600.000000  2800.000000     1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for all features. We specify custom percentile values for \n",
    "# numeric features and set include = 'all' to display statistics for categorical \n",
    "# features as well.\n",
    "df.describe(percentiles = [0.1, 0.25, 0.5, 0.75, 0.9],\n",
    "            include     = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSeqmWAjd-kG",
    "outputId": "5ba78c13-3e40-4e9c-e0bc-49e5b34407a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   YOB      1225 non-null   float64\n",
      " 1   nKIDS    1225 non-null   float64\n",
      " 2   nDEP     1225 non-null   float64\n",
      " 3   PHON     1225 non-null   int64  \n",
      " 4   dINC_SP  1225 non-null   float64\n",
      " 5   EMPS_A   1225 non-null   object \n",
      " 6   dINC_A   1225 non-null   float64\n",
      " 7   RES      1225 non-null   object \n",
      " 8   dHVAL    1225 non-null   float64\n",
      " 9   dMBO     1225 non-null   float64\n",
      " 10  dOUTM    1225 non-null   float64\n",
      " 11  dOUTL    1225 non-null   float64\n",
      " 12  dOUTHP   1225 non-null   float64\n",
      " 13  dOUTCC   1225 non-null   float64\n",
      " 14  BAD      1225 non-null   float64\n",
      "dtypes: float64(12), int64(1), object(2)\n",
      "memory usage: 143.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data overview is important to check the number of missing values and feature \n",
    "# types. The output suggests that there are no missing values and two features are\n",
    "# stored as non-numeric objects.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLp5_dlrZbTW"
   },
   "source": [
    "## 2 Data types\n",
    "You can tell from the data dictionary that the loan data includes numeric and categorical variables. Draw on the examples from [Tutorial 4](https://github.com/Humboldt-WI/bads/blob/master/tutorials/4_nb_data_preparation.ipynb) and make sure that all numeric features are stored as `float32` and all categorical features are stored as categories in your DataFame. Also, ensure that the feature `PHON` is stored as a boolean. Finally pick a suitable data type for the target variable `BAD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PHON and target variable\n",
    "#---\n",
    "df.PHON = df.PHON.astype(\"bool\")\n",
    "\n",
    "# Also convert the target. We could also make it a boolean or use an integer data type. The latter is better\n",
    "# if we plan to use the target variable values in calculations, for example, when computing model residuals.\n",
    "# We use a small integer data type for demonstration but is also fine to simply use bool here\n",
    "df.BAD = df.BAD.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T98lRbjOZbTW",
    "outputId": "e680ec81-119d-411d-8d61-be902d41778e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   YOB      1225 non-null   float64 \n",
      " 1   nKIDS    1225 non-null   float64 \n",
      " 2   nDEP     1225 non-null   float64 \n",
      " 3   PHON     1225 non-null   bool    \n",
      " 4   dINC_SP  1225 non-null   float64 \n",
      " 5   EMPS_A   1225 non-null   category\n",
      " 6   dINC_A   1225 non-null   float64 \n",
      " 7   RES      1225 non-null   category\n",
      " 8   dHVAL    1225 non-null   float64 \n",
      " 9   dMBO     1225 non-null   float64 \n",
      " 10  dOUTM    1225 non-null   float64 \n",
      " 11  dOUTL    1225 non-null   float64 \n",
      " 12  dOUTHP   1225 non-null   float64 \n",
      " 13  dOUTCC   1225 non-null   float64 \n",
      " 14  BAD      1225 non-null   uint8   \n",
      "dtypes: bool(1), category(2), float64(11), uint8(1)\n",
      "memory usage: 110.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Encode categories properly\n",
    "#---\n",
    "\n",
    "# According to the data dictionary, there are two categorical features: EMPS_A and RES.\n",
    "# As we saw in the `df.info()` command, these two features are stored as objects. \n",
    "# We need to convert them to the category format using `astype()`\n",
    "\n",
    "# We have only two features to work on and can specify these manually\n",
    "cat_features = ['EMPS_A', 'RES']  \n",
    "# Alternatively, we can use the function select_dtypes() to select features of a certain type\n",
    "cat_features = df.select_dtypes(\"object\").columns.values \n",
    "\n",
    "\n",
    "# Both of the above alternatives would give an array, which we can use to index our data frame.\n",
    "# We can then alter the data frame using that index as follows\n",
    "df[cat_features] = df[cat_features].astype('category')\n",
    "\n",
    "# Verify the conversion was successful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQvmMyMOoK12",
    "outputId": "136bd13b-3eef-4870-8a5b-9f081987529f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   YOB      1225 non-null   float32 \n",
      " 1   nKIDS    1225 non-null   float32 \n",
      " 2   nDEP     1225 non-null   float32 \n",
      " 3   PHON     1225 non-null   bool    \n",
      " 4   dINC_SP  1225 non-null   float32 \n",
      " 5   EMPS_A   1225 non-null   category\n",
      " 6   dINC_A   1225 non-null   float32 \n",
      " 7   RES      1225 non-null   category\n",
      " 8   dHVAL    1225 non-null   float32 \n",
      " 9   dMBO     1225 non-null   float32 \n",
      " 10  dOUTM    1225 non-null   float32 \n",
      " 11  dOUTL    1225 non-null   float32 \n",
      " 12  dOUTHP   1225 non-null   float32 \n",
      " 13  dOUTCC   1225 non-null   float32 \n",
      " 14  BAD      1225 non-null   uint8   \n",
      "dtypes: bool(1), category(2), float32(11), uint8(1)\n",
      "memory usage: 58.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Downcasting numerical features\n",
    "#---\n",
    "\n",
    "# There is nothing wrong with storing all numeric features as `float64`. However, \n",
    "# if memory usage becomes an issue (e.g., when working with much larger data sets), \n",
    "# we can make use of the column types to reduce memory consumption. For instance, \n",
    "# `float64` supports 15 digits of precision, whereas `float32` allows 6 digits \n",
    "# after the dot, which is often enough in practice. Furthermore, we can convert a\n",
    "# float-encoded feature to `int64` or `int32` if we know that it always takes \n",
    "# integer values only. You can check this blog post for more tips on reducing the \n",
    "# memory usage with different data types:\n",
    "# https://towardsdatascience.com/pandas-save-memory-with-these-simple-tricks-943841f8c32\n",
    "\n",
    "# For start, we once again get us an index of the numerical features...\n",
    "con_features = df.select_dtypes(\"float64\").columns.values\n",
    "df[con_features] = df[con_features].astype(\"float32\")\n",
    "\n",
    "# Verify the conversion was successful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JppjQgXwZbTW"
   },
   "source": [
    "## EDA\n",
    "### 3.1 Histogram\n",
    "The data includes a feature dINC_A, which captures the income of a credit applicant. We would expect that this feature is related to our target variable, which is called BAD in the data set. \n",
    "\n",
    "Create a histogram plot of the income feature and examine its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "1eU2Q0g3ZbTW",
    "outputId": "adce6430-6291-440a-c2d2-2f3d3fad81d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of dINC_A \n",
    "df.hist(column = 'dINC_A',  # what feature to plot\n",
    "        bins   = 25,        # number of bins\n",
    "        figsize=(8,6));     # figure size \n",
    "\n",
    "# Histogram reveals that there is a large portion of applicants (more than 200) with \n",
    "# no income. The rest is distributed between 0 and about 65.000, with most values \n",
    "# lying between 5.000 and 35.000. We also see that the right tail of distribiton\n",
    "# is rather long, indicating that the number of applicants earning at least X tends\n",
    "# to gradually decrease when X goes above 25.000 and higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctG_AqMCZbTW"
   },
   "source": [
    "The distribution reveals some potentially important insights. However, the histogram alone does not suffice to check our intuition that income and credit risk are related. To that end, let's examine the income distribution across good and bad credit applications.\n",
    "\n",
    "### 3.2 Analysis of the dependency between applicants' income and credit risk\n",
    "We begin with a manual approach, which also allows us to revisit logical indexing in Python and Pandas. Calculate the average income of a credit applicant for good risks and for bad risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YneNDUoPZbTW",
    "outputId": "8b0d6e03-8ae3-4770-e494-2d7b45c6d075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean income for GOOD risks: 23008.6426\n",
      "Mean income for BAD risks:  16316.9131\n"
     ]
    }
   ],
   "source": [
    "# Calculate the group-wise mean of dINC_A for good and bad risks using logical indexing\n",
    "m0 = df.loc[df['BAD'] == 0]['dINC_A'].mean()\n",
    "m1 = df.loc[df['BAD'] == 1]['dINC_A'].mean()\n",
    "print('Mean income for GOOD risks: {:.4f}'.format(m0)) # {:.4f} implies that we  will print a float value rounded to 4 digits after the dot\n",
    "print('Mean income for BAD risks:  {:.4f}'.format(m1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP-HaAzlZbTW"
   },
   "source": [
    "Remember that the Pandas function `groupby()` allows you to perform an analysis similar to your above calculation of the group-wise means. Replicate the previous calculation using `groupby()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmP1IHdNZbTW",
    "outputId": "eeae65dd-dfab-42cc-dd3c-541ebed9e1f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAD\n",
       "0.0    23008.642578\n",
       "1.0    16316.913086\n",
       "Name: dINC_A, dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replicate previous results using groupby()\n",
    "df.groupby('BAD')['dINC_A'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyifuA9ZZbTW"
   },
   "source": [
    "Next, we perform a graphical analysis. Depict the distribution of the income of customers with a good and bad risk, respectively, by means of a box-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "I2BTcI5RZbTW",
    "outputId": "655bd2a8-cb1c-4143-c933-cf5df86f3137"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plot\n",
    "df.boxplot(column = 'dINC_A', # feature to plot  \n",
    "           by     = 'BAD',    # feature to group by\n",
    "           figsize= (8,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA32zBM_zjku"
   },
   "outputs": [],
   "source": [
    "# Comparison of mean values and box plots confirms our intuition that BAD risks tend\n",
    "# to have lower income than GOOD risks. Remember that boxes visualize the upper \n",
    "# and lower quartiles of a feature distribution. In our case, we observe that \n",
    "# half of the GOOD applicants have income between about 12.000 and 32.000, whereas\n",
    "# half of the BAD risks have income between 0 and 26.000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjU3pxKBZbTW"
   },
   "source": [
    "### 3.3 Statistical testing\n",
    "Identify an appropriate statistical test to verify whether the observed income difference between good and bad applicants is statistically significant. Perform the test and display its results. Hint: A web-search similar to “statistical test difference in means python” will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4QmIP99ZbTW",
    "outputId": "6409a79a-4e62-41d3-f380-aa856152690d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.034214288195485554, pvalue=0.8532824134210151)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical testing of mean differences in income (i.e., feature dINC_A)\n",
    "#---\n",
    "\n",
    "# One way to perform statistical testing of mean differences is a two-sided t-test.\n",
    "# T-test checks the null hypothesis that two independent samples have identical average \n",
    "# (expected) values. In Python, t-test is implemented in several packages. The most \n",
    "# popular implementation is probably `ttest_ind()` that is part of the `scipy.stats` \n",
    "# package. Let's check the function documentation:\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "# Note that the two-sided t-test assumes equal variance within the samples by default.\n",
    "# To run the correct version of the t-test (default or adjusted for unequal variances),\n",
    "# we first need to check this assumption. One way to do that is to run a Levene test \n",
    "# for equal variances, which has the null hypothesis that variances within the samples\n",
    "# are equal. If the Levene test rejects the null hypothesis, we can perform statistical \n",
    "# testing of mean differences using Welch’s t-test modification, which does not assume\n",
    "# equal population variance, instead of the standrad t-test. This can be done simply \n",
    "# by specifying equal_var = False in the below `ttest_ind() function`.\n",
    "\n",
    "# Let's run the Levene test first:\n",
    "from scipy import stats\n",
    "stats.levene(df.loc[df['BAD'] == 0]['dINC_A'], # good risks\n",
    "             df.loc[df['BAD'] == 1]['dINC_A']) # bad risks\n",
    "\n",
    "# The `levene()` function returns the test statistic and its p-value. If you need \n",
    "# to refresh you memory on p-values, you can check out this post:\n",
    "# https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8A \n",
    "\n",
    "# In our case, Levene test does not reject the null hypothesis that variances are equal.\n",
    "# This means that we can perform a standard two-sided t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYzgN6qA3lB8",
    "outputId": "88f88b3f-0f65-42c9-a9e5-562356679b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=6.6040866243773175, pvalue=5.950120052144809e-11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now perform the t-test\n",
    "stats.ttest_ind(df.loc[df['BAD'] == 0]['dINC_A'], \n",
    "                df.loc[df['BAD'] == 1]['dINC_A'], \n",
    "                equal_var  = True)               \n",
    "\n",
    "# A very small p-value of the t-test suggests that we can reject the null hypothesis \n",
    "# at a reasonable level of signicance. This result indicates that the difference \n",
    "# in incomes between GOOD and BAD applicants is indeed statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUODqLIeZbTX"
   },
   "source": [
    "### 3.4 Categorical variables\n",
    "The data set comprises three categorical features. The feature PHON is binary and will not cause any issues. The features EMPS_A and RES are more interesting. Remember to check the data dictionary to understand what information the features encode. \n",
    "\n",
    "In the lecture, we explained that categorical features are typically encoded using dummy variables prior to applying an analytical model. Python supports dummy coding in several ways.  Pandas offers a function `get_dummies()` and sklearn offer a class `OneHotEncoder()`. The Pandas approach is maybe a bit easier to use. The more prevalent approach in practice is to rely on sklearn. \n",
    "\n",
    "Check the documentation of one or both of the above functions. Then create dummy variables for the feature RES and add them to your DataFrame.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "coLet-zEZbTX",
    "outputId": "21ca6b2f-0683-4302-d94f-24805bf3145f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOB</th>\n",
       "      <th>nKIDS</th>\n",
       "      <th>nDEP</th>\n",
       "      <th>PHON</th>\n",
       "      <th>dINC_SP</th>\n",
       "      <th>EMPS_A</th>\n",
       "      <th>dINC_A</th>\n",
       "      <th>dHVAL</th>\n",
       "      <th>dMBO</th>\n",
       "      <th>dOUTM</th>\n",
       "      <th>dOUTL</th>\n",
       "      <th>dOUTHP</th>\n",
       "      <th>dOUTCC</th>\n",
       "      <th>BAD</th>\n",
       "      <th>RES_F</th>\n",
       "      <th>RES_N</th>\n",
       "      <th>RES_O</th>\n",
       "      <th>RES_P</th>\n",
       "      <th>RES_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14464.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>464.0</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YOB  nKIDS  nDEP  PHON  dINC_SP EMPS_A   dINC_A    dHVAL    dMBO  dOUTM  \\\n",
       "0  19.0    4.0   0.0  True      0.0      R      0.0  14464.0     4.0    0.0   \n",
       "1  41.0    2.0   0.0  True      0.0      P  36000.0      0.0     0.0  280.0   \n",
       "2  66.0    0.0   0.0  True      0.0      N  30000.0      0.0     0.0    0.0   \n",
       "3  51.0    2.0   0.0  True      0.0      P    464.0  24928.0  8464.0  584.0   \n",
       "4  65.0    0.0   0.0  True      0.0      P  15000.0      0.0     0.0    0.0   \n",
       "\n",
       "   dOUTL  dOUTHP  dOUTCC  BAD  RES_F  RES_N  RES_O  RES_P  RES_U  \n",
       "0    0.0     0.0     0.0    0      0      0      1      0      0  \n",
       "1  664.0     0.0    80.0    0      0      0      1      0      0  \n",
       "2    0.0     0.0     0.0    0      0      1      0      0      0  \n",
       "3  320.0     0.0    60.0    0      0      0      1      0      0  \n",
       "4    0.0     0.0     0.0    0      0      0      0      1      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: dummy coding of RES using `get_dummies()`\n",
    "# Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "\n",
    "df_with_dummies = pd.get_dummies(df, columns = ['RES'])\n",
    "print(df_with_dummies.shape)\n",
    "df_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "3sMMaj5JSLxb",
    "outputId": "d0cf4714-b367-446f-960c-ff5c5d2d5863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOB</th>\n",
       "      <th>nKIDS</th>\n",
       "      <th>nDEP</th>\n",
       "      <th>PHON</th>\n",
       "      <th>dINC_SP</th>\n",
       "      <th>EMPS_A</th>\n",
       "      <th>dINC_A</th>\n",
       "      <th>dHVAL</th>\n",
       "      <th>dMBO</th>\n",
       "      <th>dOUTM</th>\n",
       "      <th>dOUTL</th>\n",
       "      <th>dOUTHP</th>\n",
       "      <th>dOUTCC</th>\n",
       "      <th>BAD</th>\n",
       "      <th>x0_F</th>\n",
       "      <th>x0_N</th>\n",
       "      <th>x0_O</th>\n",
       "      <th>x0_P</th>\n",
       "      <th>x0_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14464.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>464.0</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YOB  nKIDS  nDEP  PHON  dINC_SP EMPS_A   dINC_A    dHVAL    dMBO  dOUTM  \\\n",
       "0  19.0    4.0   0.0  True      0.0      R      0.0  14464.0     4.0    0.0   \n",
       "1  41.0    2.0   0.0  True      0.0      P  36000.0      0.0     0.0  280.0   \n",
       "2  66.0    0.0   0.0  True      0.0      N  30000.0      0.0     0.0    0.0   \n",
       "3  51.0    2.0   0.0  True      0.0      P    464.0  24928.0  8464.0  584.0   \n",
       "4  65.0    0.0   0.0  True      0.0      P  15000.0      0.0     0.0    0.0   \n",
       "\n",
       "   dOUTL  dOUTHP  dOUTCC  BAD  x0_F  x0_N  x0_O  x0_P  x0_U  \n",
       "0    0.0     0.0     0.0    0   0.0   0.0   1.0   0.0   0.0  \n",
       "1  664.0     0.0    80.0    0   0.0   0.0   1.0   0.0   0.0  \n",
       "2    0.0     0.0     0.0    0   0.0   1.0   0.0   0.0   0.0  \n",
       "3  320.0     0.0    60.0    0   0.0   0.0   1.0   0.0   0.0  \n",
       "4    0.0     0.0     0.0    0   0.0   0.0   0.0   1.0   0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: dummy coding of RES using `OneHotEncoder()`\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "# Applying sklearn encoders involves several steps:\n",
    "# - initializing the encoder and specifying its properties\n",
    "# - fitting the encoder to the data\n",
    "# - transforming the data using the encoder\n",
    "# - [if applied to specific columns] merging the result to the original data\n",
    "\n",
    "# Initializing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore', # treatment of unknown categories\n",
    "                    sparse         = False)    # whether to return numpy array or sparse matrix\n",
    "\n",
    "# Fitting encoder to a specific column. If we supply the whole dataframe, the \n",
    "# encoder will fit and then transform all columns. We only want to change one.\n",
    "enc.fit(df[['RES']])\n",
    "\n",
    "# Transforming the data / column\n",
    "df_transformed = enc.transform(df[['RES']])\n",
    "\n",
    "# Merging dummies to the data with `join()`. Note that the output of the sklearn \n",
    "# encoders is a numpy array or a sparce matrix. If necessary, you would need to \n",
    "# convert the array back to pandas dataframe. This is what we do below.\n",
    "df_transformed = pd.DataFrame(df_transformed, \n",
    "                              columns = enc.get_feature_names()) # dummy names\n",
    "df_with_dummies_2 = df.join(df_transformed)\n",
    "\n",
    "# Deleting original variable\n",
    "del df_with_dummies_2['RES']\n",
    "print(df_with_dummies_2.shape)\n",
    "df_with_dummies_2.head()\n",
    "\n",
    "# As you can see, pandas `get_dummies()` approach is much simpler. However, learning\n",
    "# the logic behind sklearn processors is very useful as there are many different \n",
    "# processors that can be applied to a data set using the same pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mpw-Plv6ZbTX"
   },
   "source": [
    "The feature EMPS_A has more distinct levels. Considering the previous task, it is obvious that dummy coding the feature will increase dimensionality substantially. To avoid this, it makes sense to **regroup** the category levels prior to dummy coding. \n",
    "\n",
    "In the lecture on data preparation, we argued that a pivot table helps to identify category levels that we can merge. Specifically, we were recommending merging category levels for which the odds-ratio (i.e., the ratio of goods to bads) is similar. Write code to calculate the odds ratio for each level of the feature EMPS_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BakLWSopZbTX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BAD</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>odds_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMPS_A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>88</td>\n",
       "      <td>36</td>\n",
       "      <td>2.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>413</td>\n",
       "      <td>118</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>1.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>86</td>\n",
       "      <td>37</td>\n",
       "      <td>2.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>187</td>\n",
       "      <td>44</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BAD       0    1  odds_ratio\n",
       "EMPS_A                      \n",
       "B        22    8    2.750000\n",
       "E        88   36    2.444444\n",
       "M        17    6    2.833333\n",
       "N         5    1    5.000000\n",
       "P       413  118    3.500000\n",
       "R        55   49    1.122449\n",
       "T        86   37    2.324324\n",
       "U         4    4    1.000000\n",
       "V       187   44    4.250000\n",
       "W        21   16    1.312500\n",
       "Z         4    4    1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculation of the odds-ratio for EMPS_A\n",
    "\n",
    "# Creating cross-tab of EMPS_A and BAD\n",
    "res = pd.crosstab(df['EMPS_A'], df['BAD'])\n",
    "\n",
    "# Computing odds ratio\n",
    "res['odds_ratio'] = res[0] / res[1]\n",
    "\n",
    "# Displaying the output\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7o1mgFkibZ3j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BAD</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>odds_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMPS_A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>1.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>86</td>\n",
       "      <td>37</td>\n",
       "      <td>2.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>88</td>\n",
       "      <td>36</td>\n",
       "      <td>2.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>413</td>\n",
       "      <td>118</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>187</td>\n",
       "      <td>44</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BAD       0    1  odds_ratio\n",
       "EMPS_A                      \n",
       "U         4    4    1.000000\n",
       "Z         4    4    1.000000\n",
       "R        55   49    1.122449\n",
       "W        21   16    1.312500\n",
       "T        86   37    2.324324\n",
       "E        88   36    2.444444\n",
       "B        22    8    2.750000\n",
       "M        17    6    2.833333\n",
       "P       413  118    3.500000\n",
       "V       187   44    4.250000\n",
       "N         5    1    5.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's sort the results by odds ratio:\n",
    "res = res.sort_values('odds_ratio')\n",
    "res\n",
    "\n",
    "# As you can see, some values of EMPS_A have the same odds ratio (U and Z). Some\n",
    "# other values also have a similar ratio (e.g., B and M)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecbHtEs1ZbTX"
   },
   "source": [
    "Now merge some category levels based on your solution to the previous task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWkDlvAUZbTX",
    "outputId": "933ccfc7-ab62-4e92-a530-fd8619f1d088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P+V+N      768\n",
       "T+E+B+M    300\n",
       "U+Z+R+W    157\n",
       "Name: EMPS_A_merged, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on the previous results, we can merge some levels of EMPS_A with each other\n",
    "# if they have a similar odds ratio. One solution could be to do the following encoding:\n",
    "# - level 1: ['U', 'Z', 'R', 'W']\n",
    "# - level 2: ['T', 'E', 'B', 'M']\n",
    "# - level 3: ['P', 'V']\n",
    "# - level 4: ['N']\n",
    "\n",
    "# How to do the merging? Let's start by setting up a renaming dictionary\n",
    "remap_dict = {\n",
    "    'U': 'U+Z+R+W',\n",
    "    'Z': 'U+Z+R+W',\n",
    "    'R': 'U+Z+R+W',\n",
    "    'W': 'U+Z+R+W',\n",
    "    'T': 'T+E+B+M',\n",
    "    'E': 'T+E+B+M',\n",
    "    'B': 'T+E+B+M',\n",
    "    'M': 'T+E+B+M',\n",
    "    'P': 'P+V+N',\n",
    "    'V': 'P+V+N',\n",
    "    'N': 'P+V+N'}\n",
    "\n",
    "# Now we can use `.map()` to merge category levels according to the dictionary\n",
    "df['EMPS_A_merged'] = df['EMPS_A'].map(remap_dict).astype('category')\n",
    "\n",
    "# Checking value counts\n",
    "df['EMPS_A_merged'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8MCuM_NZbTX"
   },
   "source": [
    "The advantage of merging category levels is that we need less dummy variables for encoding the feature. On the other hand, by reducing category levels, we run the risk of losing information. It would make sense to check that our previous merging of category levels did not hurt, e.g., was not too aggressive. Why aggressive? Well, imagine you merge all category levels into one level. This would render the feature useless. So there is a trade-off between having few levels, to not increase dimensionality, and not having too few levels, to sustain the information in the feature for distinguishing good and bad applicants. To find a healthy balance between these conflicting objectives, we need a measure that tells us whether a grouping is informative. It turns out that a well-known statistical test, namely the $\\chi^2$ test, provides this functionality. \n",
    "- Run a quick web search to revisit the $\\chi^2$ test and understand how it is useful for judging a grouping of EMPS_A in our context.\n",
    "- Identify a way to calculate the $\\chi^2$ test statistic in Python\n",
    "- Calculate the test statistic for the original version of EMPS_A with 11 levels and the new version with less levels (i.e., solution to previous task)\n",
    "- Interpret the results and conclude whether your encoding of EMPS_A is suitable\n",
    "\n",
    "*HINT:* When merging categories, you should expect $\\chi^2$ test statistic to decrease unless the merged categories have exactly the same odds ratio. When deciding how many (and which) categories to merge, we should balance two conflicting objectives and try reducing the number of categories such that not too much information is lost. When fixing the number of categories, you can use the $\\chi^2$ test to compare competing encodings to select the one that preserves the most information. Play around with different ways to merge categories and try to select the one that achieves a good balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VoIfL6gZbTX",
    "outputId": "88465a42-f988-4434-dd63-5108421c9a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: Chi-square statistic with 10 degrees of freedom is 45.78 (p-value=0.000002)\n",
      "Merged data: Chi-square statistic with 2 degrees of freedom is 44.30 (p-value=0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Chi^2 testing of categorical features can be performed with `chi2_contingency()`\n",
    "# from `scipy.stats`. The documentation is provided at:\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "\n",
    "# Importing packages\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Testing the original EMPS_A encoding\n",
    "# Note that `chi2_contingency()` return 4 values: test statistic, p-value, degrees \n",
    "# of freedom, expected frequencies. We only need the test statistic and can ignore\n",
    "# the rest. Using _ as a name of the variable to save the output of a function implies\n",
    "# that we ignore this output and do not store it in the memory.\n",
    "ct_orig = pd.crosstab(df['BAD'], df['EMPS_A'])\n",
    "stat_orig, pval_orig, dof_orig, _ = chi2_contingency(ct_orig)\n",
    "\n",
    "# Testing the modified EMPS_A encoding\n",
    "ct_merged = pd.crosstab(df['BAD'], df['EMPS_A_merged'])\n",
    "stat_merged, pval_merged, dof_merged, _ = chi2_contingency(ct_merged)\n",
    "\n",
    "# Comparing test results\n",
    "print('Original data: Chi-square statistic with {:.0f} degrees of freedom is {:.2f} (p-value={:.6f})'.format(dof_orig, stat_orig, pval_orig))\n",
    "print('Merged data: Chi-square statistic with {:.0f} degrees of freedom is {:.2f} (p-value={:.6f})'.format(dof_merged, stat_merged, pval_merged))\n",
    "\n",
    "# You can take the following read for more details on Chi^2 tests:\n",
    "# https://machinelearningmastery.com/chi-squared-test-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1638961571487,
     "user": {
      "displayName": "Stefan Lessmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihtuVUIO07jrZ6NKEVggi44vrPvluMzUCsHoZh=s64",
      "userId": "06342662613942148717"
     },
     "user_tz": -60
    },
    "id": "rB4k-atpdx-U"
   },
   "outputs": [],
   "source": [
    "# Let's interpret the test results. We know that the maximum statistic value (in \n",
    "# our case, it is 45.78) is always observed with the original encoding. We could \n",
    "# keep the same statistic value if we only merged U and Z, but that would only reduce \n",
    "# the number of categories from 11 to 10. Merging more categories decreases the \n",
    "# statistic but it matters which categories we merge to have a smaller reduction.\n",
    "# More specifically, it costs less to merge categories that have more similar odds ratio.\n",
    "\n",
    "# In our example, we are able to reduce the number of categories from 11 to 4 at a \n",
    "# very small reduction of the Chi^2 statistic from 45.78 to 44.30. This indicates \n",
    "# that our solution preserves most of the information despite the fact that we dropped\n",
    "# 7 categories. This appears to be a good balance between the cardinality and predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0v5WATBZbTX"
   },
   "source": [
    "# Well done. You did great in solving all the exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z6Oqmf-ZbTX"
   },
   "source": [
    "**Optional**\n",
    "By solving the previous task, you created a rather powerful mechanism to regroup categorical variables and judge the predictive power of the encoding prior to applying dummy coding. Write a function that wraps-up this functionality. In particular, your function should:\n",
    "- receive a categorical variable as input\n",
    "- check that the variable is actually a category\n",
    "- determine the number of unique levels\n",
    "- iteratively reduce the number of levels by:\n",
    "  - calculating the odds-ratio of all current levels\n",
    "  - merging the two levels whose odds ratio is most similar\n",
    "  - calculating the $\\chi^2$ statistic for the current grouping and store its value\n",
    "- plot the elbow curve for the $\\chi^2$ statistic against the number of levels\n",
    "- display the optimal encoding for each number of levels\n",
    "\n",
    "*HINT:* recall the elbow curve showing relationship between the distance and the number of clusters that we plotted in [Tutorial 2](https://github.com/Humboldt-WI/bads/blob/master/tutorials/2_nb_descriptive_analytics.ipynb). Your function should output a similar graph.\n",
    "\n",
    "Finally, check your implementation by applying the function to EMPS_A and interpreting the results.\n",
    "\n",
    "Note that the described procedure mimics the logic behind the [CHAID tree](https://towardsdatascience.com/clearly-explained-top-2-types-of-decision-trees-chaid-cart-8695e441e73e), which is a tree-based supervised learning algorithm that finds feature splits based on the $\\chi^2$ statistic. When pruning the CHAID tree, feature splits with the lowest value of the $\\chi^2$ statistic are removed, which is similar to what we do when merging categories such that the drop in the $\\chi^2$ statistic value is as small as possible. In the next turorials, you will learn more about tree-based algorithms and implement a decision tree from scratch. Solving this exercise will help you to make a step towards a better understanding of the principles of these learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Jyw0-6wRZbTX"
   },
   "outputs": [],
   "source": [
    "# We will define a function that \n",
    "def optimize_grouping(cat_feature, target_feature):\n",
    "    '''\n",
    "    Compares differenct encodings of a categorical variable using Chi^2 test.\n",
    "\n",
    "    Input:\n",
    "    - cat_feature: categorical feature to be encoded\n",
    "    - target_feature: target feature\n",
    "\n",
    "    Output:\n",
    "    - vector of Chi^2 statistic values\n",
    "    - vector of p-values associated with the Chi^2 tests\n",
    "    '''\n",
    "\n",
    "    # Copying features to avoid editing the original DataFrame\n",
    "    cat_feature    = cat_feature.copy()\n",
    "    target_feature = target_feature.copy()\n",
    "\n",
    "    # Checking if feature is categorical\n",
    "    if cat_feature.dtype != 'category':\n",
    "        print('Input feature is not categorical. Received feature of type:', cat_feature.dtype)\n",
    "        return\n",
    "\n",
    "    # Placeholders for Chi^2 values and categories\n",
    "    chi_stats= []\n",
    "    pvals    = []\n",
    "    cats     = []\n",
    "    cats_num = []\n",
    "\n",
    "    # Storing number and values of categories\n",
    "    n_unique = cat_feature.nunique()\n",
    "    cats_num.append(n_unique)\n",
    "    cats.append(cat_feature.cat.categories)\n",
    "\n",
    "    # Performing chi2 test\n",
    "    ct = pd.crosstab(cat_feature, target_feature)\n",
    "    stat, pv, _, _ = chi2_contingency(ct)\n",
    "    chi_stats.append(stat)\n",
    "    pvals.append(pv)\n",
    "\n",
    "    # Iteratively trying different groupings\n",
    "    for i in range(n_unique - 1):\n",
    "\n",
    "        # Computing odds ratio\n",
    "        ct = pd.crosstab(cat_feature, target_feature)\n",
    "        ct['odds_ratio'] = ct[0] / ct[1]\n",
    "\n",
    "        # Finding min odds ratio difference using the function diff()\n",
    "        # diff() computes the difference between adjacent rows in a data frame.\n",
    "        # Prior sorting of the data frame ensures that we compute the difference between neighboring entries. \n",
    "        ct = ct.sort_values('odds_ratio')\n",
    "        ct['odds_ratio_diff'] = ct['odds_ratio'].diff()\n",
    "        # Last step is to find the index of the row with minimum difference, which we achieve using Nump's where() function.\n",
    "        # Do not worry about the last two brackets. The implementation of numpy.where() requries this way of indexing the output \n",
    "        min_idx = np.where(ct['odds_ratio_diff'] == ct['odds_ratio_diff'].min())[0][0]\n",
    "\n",
    "        # Storing levels to merge\n",
    "        levels_to_merge = ct.iloc[(min_idx - 1):(min_idx + 1)].index.values\n",
    "\n",
    "        # Merging two categories with add_categories()\n",
    "        new_level = '+'.join(levels_to_merge)  # Label of the new category level; we arbitrarily select the plus sign as seperator\n",
    "        cat_feature.cat.add_categories(new_level, inplace = True)\n",
    "        for level in levels_to_merge:\n",
    "            cat_feature.loc[cat_feature == level] = new_level\n",
    "        \n",
    "        # We can now remove the two category levels that were just merged    \n",
    "        cat_feature.cat.remove_categories(levels_to_merge, inplace = True)\n",
    "\n",
    "        # Storing number and values of categories after encoding\n",
    "        cats_num.append(cat_feature.nunique())\n",
    "        cats.append(cat_feature.cat.categories)\n",
    "\n",
    "        # Performing chi2 test for merged category\n",
    "        ct = pd.crosstab(cat_feature, target_feature)\n",
    "        stat, pv, _, _ = chi2_contingency(ct)\n",
    "        chi_stats.append(stat)\n",
    "        pvals.append(pv)\n",
    "    \n",
    "    # Plotting results\n",
    "    plt.plot(cats_num, chi_stats)\n",
    "    plt.title('Chi^2 Elbow Curve')\n",
    "    plt.ylabel('Chi^2 statistic')\n",
    "    plt.xlabel('Number of categories')\n",
    "    plt.show()\n",
    "\n",
    "    # Printing encodings\n",
    "    for i in range(len(cats)):\n",
    "        print('- {} categories: {}'.format(cats_num[i], cats[i].values))\n",
    "\n",
    "    # Returning Chi^2 values and encodings\n",
    "    return stats, cats, pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "z3KtwzJIlKP7",
    "outputId": "10c0acc5-b971-4b8e-9802-cfa244dccbd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 10 categories: ['B' 'E' 'M' 'N' 'P' 'R' 'T' 'V' 'W' 'U+Z']\n",
      "- 9 categories: ['E' 'N' 'P' 'R' 'T' 'V' 'W' 'U+Z' 'B+M']\n",
      "- 8 categories: ['N' 'P' 'R' 'V' 'W' 'U+Z' 'B+M' 'T+E']\n",
      "- 7 categories: ['N' 'P' 'V' 'W' 'B+M' 'T+E' 'U+Z+R']\n",
      "- 6 categories: ['N' 'P' 'V' 'B+M' 'T+E' 'U+Z+R+W']\n",
      "- 5 categories: ['N' 'P' 'V' 'U+Z+R+W' 'T+E+B+M']\n",
      "- 4 categories: ['N' 'U+Z+R+W' 'T+E+B+M' 'P+V']\n",
      "- 3 categories: ['N' 'U+Z+R+W' 'T+E+B+M+P+V']\n",
      "- 2 categories: ['U+Z+R+W' 'T+E+B+M+P+V+N']\n",
      "- 1 categories: ['U+Z+R+W+T+E+B+M+P+V+N']\n"
     ]
    }
   ],
   "source": [
    "# Let's apply our function and inspect the output\n",
    "stats, cats, pvalues = optimize_grouping(cat_feature = df['EMPS_A'], target_feature = df['BAD'])\n",
    "\n",
    "# The output suggests that reducing the number of categories from 11 to 4 allows to\n",
    "# preserve most of the information. The suggested endcoing ['N' 'U+Z+R+W' 'T+E+B+M' 'P+V']\n",
    "# corresponds to our encoding selected in the previous task, which is good news :)\n",
    "# Further reducing the number of categories to 3 or 2 results in a rather sharp drop\n",
    "# in the Chi^2 test statistic, which suggests that stopping at 4 appears to be a \n",
    "# good solutiion. Well done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_ex_data_prep_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PyCharm (VHB-ProDok-Internal)",
   "language": "python",
   "name": "pycharm-e3448bea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
